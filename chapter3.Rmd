# **Logistic regression**

__Summary of week3 study__


+ _In week3, I self-studied some data wrangling skills (join,mutate etc.), logistic regression, cross validation from  [DataCamp](https://campus.datacamp.com/courses/helsinki-open-data-science/logistic-regression?ex=1);_

+ _Logistic regression is about modeling categorical targets using related variables_

```{r}
## Loading packages
library(dplyr)
library(tidyr)
library(ggplot2)
library(GGally)
library(boot)
```

## 1. Read the data
In this week, we will use logisitic regression to build a model to predict alcohol consumption (AC). The data is processed from the [online data](https://archive.ics.uci.edu/ml/datasets/Student+Performance). There are two questionaires in the website. I have used 13 variables of both (`school`,`sex`,`age`,`address`,`famsize`,`Pstatus`,`Medu`,`Fedu`,`Mjob`,`Fjob`,`reason`,`nursery`,`internet`) to join the data. The remaining data is combined as mean if they are numeric or kept if they are other data types.

```{r}
## Reading data to alc 
data <- "/Users/qingli/Documents/GitHub/IODS-project/Data/processed_alc_data_w3.csv"
alc <- read.csv(data)
colnames(alc)
str(alc)
```

The explanations for the variables:

+ `school` -  student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)
+`sex` - student's sex (binary: 'F' - female or 'M' - male) 
+ `age` - student's age (numeric: from 15 to 22) 
+ `address` - student's home address type (binary: 'U' - urban or 'R' - rural) 
+ `famsize` - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) 
+ `Pstatus` - parent's cohabitation status (binary: 'T' - living together or 'A' - apart) + `Medu` - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 = 5th to 9th grade, 3 = secondary education or 4 = higher education) 
+ `Fedu` - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2  =  5th to 9th grade, 3 =  secondary education or 4 = higher education) 
+ `Mjob` - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') 
+ `Fjob` - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') 
+ `reason` - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') 
+ `guardian` - student's guardian (nominal: 'mother', 'father' or 'other') 
+ `traveltime` - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour) 
+ `studytime` - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours) 
+ `failures` - number of past class failures (numeric: n if 1<=n<3, else 4) 
+ `schoolsup` - extra educational support (binary: yes or no) 
+ `famsup` - family educational support (binary: yes or no) 
+ `paid` - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) 
+ `activities` - extra-curricular activities (binary: yes or no) 
+ `nursery` - attended nursery school (binary: yes or no) 
+ `higher` - wants to take higher education (binary: yes or no) 
+ `internet` - Internet access at home (binary: yes or no) 
+ `romantic` - with a romantic relationship (binary: yes or no) 
+ `famrel` - quality of family relationships (numeric: from 1 - very bad to 5 - excellent) 
+ `freetime` - free time after school (numeric: from 1 - very low to 5 - very high) 
+ `goout` - going out with friends (numeric: from 1 - very low to 5 - very high) 
+ `Dalc` - workday alcohol consumption (numeric: from 1 - very low to 5 - very high) 
+ `Walc` - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) 
+ `health` - current health status (numeric: from 1 - very bad to 5 - very good) 
+ `absences` - number of school absences (numeric: from 0 to 93)

These grades are related with the course subject, Math or Portuguese: 

+ `G1` - first period grade (numeric: from 0 to 20) 
+ `G2` - second period grade (numeric: from 0 to 20) 
+ `G3` - final grade (numeric: from 0 to 20, output target)

## 2. Select alcohol consumption (AC) related variables

To predict the alcohol consumption, I think the folowing variables might be associated:

+ `paid`: the extra money can help to buy alcohol.
+ `goout`: there will be more chance to drink alcohol with friends if they go out very often.
+ `famrel`: people with higher AC are unlikely to have bad family relationships.
+ `absences`: number of school absences is a sign for who drinks often and cannot make to school.

## 3. Explore the relationship between the selected variables with alcohol consumption (AC)

```{r}
## high_use vs paid
alc %>% group_by(paid,high_use) %>% summarise(count=n())
```

The student got extra paid or not seemed not affect AC.

```{r,fig.height=3,fig.width=4}
## high_use vs goout
high_AC_goout_mean <- mean(alc$goout[alc$high_use == "TRUE"])
low_AC_goout_mean <- mean(alc$goout[alc$high_use == "FALSE"])

print(c("high AC group goout_mean",high_AC_goout_mean,
        "low AC group goout_mean",low_AC_goout_mean))

g1 <- ggplot(alc, aes(x = high_use, y = goout,col=paid)) + geom_boxplot() +
  ggtitle("goout by high_use") + ylab("go_out freq") +xlab("achohol consumption")

g1
```

The students who have higher AC are more frequently going out with friends. The mean goout frequency for higher AC group is 3.7 compared with 2.8 in lower AC group.

```{r,fig.height=3,fig.width=4}
## high_use vs family relationship
high_AC_famrel_mean <- mean(alc$famrel[alc$high_use == "TRUE"])
low_AC_famrel_mean <- mean(alc$famrel[alc$high_use == "FALSE"])
print(c("high AC group family relationship status:",
        high_AC_famrel_mean,"low AC group family relationship status:",low_AC_famrel_mean))
g2 <- ggplot(alc, aes(x = high_use, y = famrel)) + geom_boxplot() +
 ggtitle("family relationship by high_use") +ylab("family relationship status") +xlab("achohol consumption")
g2
```

The family relationship status in students with higher AC and lower AC does not show a big difference from the mean of both group (3.7 and 4.0, respectively). But it looks different from the boxplot.

```{r,fig.height=3,fig.width=4}
## high_use vs absence
high_AC_absence_mean <- mean(alc$health[alc$high_use == "TRUE"])
low_AC_absence_mean <- mean(alc$health[alc$high_use == "FALSE"])

print(c("high_AC group absence times (mean):",high_AC_absence_mean,
        "low_AC group absence times (mean):",low_AC_absence_mean))
g3 <- ggplot(alc, aes(x = high_use, y = absences, col=paid)) +
 geom_boxplot() + ggtitle("absence by high_use") +ylab("absence times") +xlab("achohol consumption")
g3
```

The absence times in students with higher AC and lower AC does not show a big difference from the mean of both group (3.7 and 3.5, respectively). It slightly changed in boxplot, where the higher AC group shows more absence times.

## 4. Logistic regression

```{r}
m <- glm(high_use ~ paid + goout + famrel + absences, data = alc, family = "binomial")
summary(m)
```

+ `Intercept`: -2.56121, is the log odds of a student with higher AC when other variables are zero/paid.no.
+ The logistic regression model shows `goout` and `absences` are the most two most important explanatory variables in the model with significant low `p-value`. `famrel` follows them with less significant `p-value`. Surprisingly, `paid.yes` not does contribute to AC that much.
+ Coefficients for the variables (e.g. 0.775 for `goout`) is the expected change in log odds for a one-unit increase of `goout` in this case.
+ Coefficient for `paiedyes` is measured by `Wald test` which takes `yes` in categorical variable `paid` as the reference class compared to those are not. 

```{r}
odd_ratio <- coef(m) %>% exp
CI <- confint(m) %>% exp
cbind(odd_ratio,CI)
```
+ The odds ratio for `Intercept`(0.07) means the odds of being higher AC is 0.07 times of the odds being lower AC when other variables are zero.
+ The odds ratio for `paidyes` means the odds for `paidyes` are about 1.35 times of the odds for `paidno`, and in the range of values [0.83100065 2.2091855] that you can be 95% certain to find the true mean of the OR.
+ The odds ratios and 95 confidence intervals are listed for other three numeric variables (e.g. `goout`). The odds of being higher AC is 2.17 times higher than the odds of being lower AC if we increase goout a one-unit higher. The range of [1.72550406 2.7679697] is that we can be 95% certain to find the true mean of the OR.

Therefore, we are only considering the significantly contirbuted variables in our new model which will be used for prediction.

```{r}
m_new <- glm(high_use ~ goout + famrel + absences, data = alc, family = "binomial")
summary(m_new)
```

## 5. Model prediction
```{r,fig.height=3,fig.width=5}
## use the new model to predict the probabilities for each sample
probabilities <- predict(m_new, type = "response")

## add probabilities and prediction to alc
alc <- mutate(alc, probabilities = probabilities)
alc <- mutate(alc, prediction = probabilities>0.5)

## calculate 2x2 cross tabulation of predictions versus the actual values 
table(high_use = alc$high_use, prediction = alc$prediction)

## calculate 2x2 cross tabulation of predictions versus the actual values in proportion
ggplot(alc, aes(x = probabilities, y =high_use,col = prediction)) + geom_point()
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table %>% addmargins
```
From the prediction result, there are 75.6% (`0.63874346+0.11780105=0.7565445`) of the samples out of 382 samples are accuretely predicted by our model.

```{r}
## the mean prediction error
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5 ## the class is either 'TRUE'(1) or 'FALSE' (0). 
  mean(n_wrong)
}
## call the loss function to calculate the wrong prediction rate
loss_func(class = alc$high_use, prob = alc$probabilities)
```

Thus, the error prediction rate is around 24.3%, which matches with our accuracy rate `1-accuracy rate(75.6%)`.

## 6. Cross validation for model performance validation

```{r}
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m_new, K = 10)
cv$delta[1]
```
The prediction error for the current new model is 0.248.

```{r}
m_tutorial <- glm(high_use ~ failures + absences + sex, data = alc, family = "binomial")
cv_tutorial <- cv.glm(data = alc, cost = loss_func, glmfit = m_tutorial, K = 10)
cv_tutorial$delta[1]
```
The prediction error for the model given in the tutorial is 0.259, which is higher than our current model. Our model shows better performance.

## 7. Model comparison

```{r}
## Use 8 variables as predictors
m1 <- glm(high_use ~ failures + absences + sex + paid + goout + famrel + higher + famsize, data = alc, family = "binomial")
## summary the model
summary (m1)

## For training data
probabilities_m1 <- predict(m1, type = "response")
m1_ave_wrong_pred <- loss_func(class = alc$high_use, prob = probabilities_m1)
m1_ave_wrong_pred
## For testing data
cv_m1 <- cv.glm(data = alc, cost = loss_func, glmfit = m1, K = 10)
cv_m1_wrong_pred <- cv_m1$delta[1]
cv_m1_wrong_pred
```

In the above model, we used 8 variables to predict AC. There are 5 variables (`absences`,`sexM`,`paidyes`,`goout`,`famrel`) are sifnificantly contributed to AC. The other three `failures`,`higheryes` and `famsizeLE3`are not contributed to AC. For this model, we have the prediction errors are 0.2146597 and 0.2329843 for the training and testing data, which is not too much better than our three varialbes `goout` + `famrel` + `absences` model (0.24).

**To draw prediction error for the traning and testing data for different model, we will then creat a dataframe to collect all the data as fellows:**

```{r}
## for the variables numbers 8,7,6,5 and 4 will be used for 5 models. For each of the model, we will collect its prediction error for training and testing data. So there are 10 vectors. 
model_name <- NULL ## model name for each one, identified by their prediction variable numbers
types <- NULL ## to distinguish two types of prediction error for each model
values_collection<- replicate(10,0) ## initialize prediction error vector to ten zeros
## change the fisrt two prediction error values for model8
values_collection[c(1,2)] <- c(m1_ave_wrong_pred,cv_m1_wrong_pred) 

## Change the model names and types using a loop:
for (i in c(8,7,6,5,4)){
  model_name <- c (model_name, replicate(2,paste("model",i,sep='')) )
  types <- c(types, c("traning","testing"))
}

## give the three vectors to our model collection dataframe.
model_collection <- data.frame(model=model_name,pred_error=values_collection,used_data=types)
## print model collection
model_collection
```

**Now, we will call different models and collect their prediction erros to our model collection dataframe.**

```{r}
## for model7:
m <- glm(high_use ~ failures + absences + sex + paid + goout + famrel + higher, data = alc, family = "binomial")
## For training data
probabilities_m <- predict(m, type = "response")
m_ave_wrong_pred <- loss_func(class = alc$high_use, prob = probabilities_m)
## For testing data
cv_m <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)
cv_m_wrong_pred <- cv_m$delta[1]
values_collection[c(3,4)] <- c(m_ave_wrong_pred,cv_m_wrong_pred) 

## for model6:

m <- glm(high_use ~ failures + absences + sex + paid + goout + famrel, data = alc, family = "binomial")
## For training data
probabilities_m <- predict(m, type = "response")
m_ave_wrong_pred <- loss_func(class = alc$high_use, prob = probabilities_m)
## For testing data
cv_m <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)
cv_m_wrong_pred <- cv_m$delta[1]
values_collection[c(5,6)] <- c(m_ave_wrong_pred,cv_m_wrong_pred)

## for model5:

m <- glm(high_use ~ absences + sex + paid + goout + famrel, data = alc, family = "binomial")
## For training data
probabilities_m <- predict(m, type = "response")
m_ave_wrong_pred <- loss_func(class = alc$high_use, prob = probabilities_m)
## For testing data
cv_m <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)
cv_m_wrong_pred <- cv_m$delta[1]
values_collection[c(7,8)] <- c(m_ave_wrong_pred,cv_m_wrong_pred)

## for model4:

m <- glm(high_use ~ absences + sex + goout + famrel, data = alc, family = "binomial")
## For training data
probabilities_m <- predict(m, type = "response")
m_ave_wrong_pred <- loss_func(class = alc$high_use, prob = probabilities_m)
## For testing data
cv_m <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)
cv_m_wrong_pred <- cv_m$delta[1]
values_collection[c(9,10)] <- c(m_ave_wrong_pred,cv_m_wrong_pred)
values_collection
```
We have collected all the prediction errors for all models. Next, we will draw the figure to compare them.

```{r,fig.height==3,fig.width=5}
model_order<-paste ("model",c(8,7,6,5,4),sep="")
model_collection$model <- factor(model_collection$model,levels=as.vector(model_order))
model_collection$pred_error <- values_collection
model_collection
ggplot(model_collection,aes(x=model,y=pred_error,col=used_data, group=used_data)) +geom_point() + geom_line()
```

The above figure shows the model with decreasing variable numbers behaves better than those higher predictors ones. The reason for that probably is casued by over-fitting when too many variables used in the model. It means higher predictors will not ensure the better performance.

